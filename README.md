# 什麼是AI神經網路及AI的基本概念

---

### 🔹 什麼是人工智慧（AI）？

**人工智慧（Artificial Intelligence，簡稱 AI）** 是一種讓電腦或機器「模仿人類智慧」的技術。  
它可以讓電腦執行一些原本需要人腦才能完成的工作，例如：

- 認圖（像是人臉辨識）
- 聽懂語音（像 Siri、Google 助理）
- 玩遊戲（像 AlphaGo）
- 預測（像天氣預測、股市走勢）

AI 不只是程式碼，它是透過**學習資料**來改善自己的表現。

這次上課主要是認圖方面的專案

---

### 🔹 什麼是神經網路（Neural Network）？

神經網路是實現 AI 的一種**重要技術**。  
它是**模仿人腦運作方式**而設計出來的模型。

就像人腦由很多神經元（Neurons）連接起來，神經網路也是由**很多「節點」或「人工神經元」組成的網路**，這些節點會根據輸入資料來做出判斷。

---

### 🔸 神經網路的基本概念

一個神經網路大致分成三個部分：

1. **輸入層（Input Layer）**  
   - 負責接收資料（例如圖片的像素值、音訊的波形）
   - 每個節點對應一個特徵

2. **隱藏層（Hidden Layer）**  
   - 真正處理資料的地方
   - 可以有一層或多層
   - 每個節點會做數學運算，然後傳遞到下一層
   - 這些層會學會如何從輸入資料中找出**模式（pattern）**

3. **輸出層（Output Layer）**  
   - 輸出結果（例如：這是「狗」還是「貓」）

---

### 🔹 節點在做什麼？

每個節點會做這幾件事：

1. **接收前一層的輸入**
2. **加權相加（加上每個輸入對應的權重）**
3. **加上偏差值（bias）**
4. **丟進激活函數（activation function）產生輸出**
   - 激活函數可以讓神經網路變得「非線性」，有更強的表現力

動畫：https://www.youtube.com/embed/Aop4rGjMskI?si=F0vzRe9fSPPZOHyV

---

### 🔸 學習的方式：反向傳播

神經網路透過一種叫 **「反向傳播（Backpropagation）」** 的方法學習：

1. 比較預測值與正確答案的差距（也就是「誤差 (error)」）
2. 用誤差來調整每個權重（讓下一次表現更好）
3. 重複很多次，直到結果滿意為止

---

## ➕ 加法、✖️ 乘法（點乘、矩陣乘法）與 Hadamard 乘積說明

在人工智慧（AI）和神經網路中，**向量和矩陣的運算**是很基本也非常重要的工具。我們常會遇到以下幾種運算方式：

---

### 🔹 向量或矩陣的「加法」

矩陣或向量的加法非常直覺，就是「**同位置相加**」。

#### ✏️ 例子：
如果有兩個向量：

```
A = [1, 2, 3]  
B = [4, 5, 6]
```

它們相加就是：

```
A + B = [1+4, 2+5, 3+6] = [5, 7, 9]
```

✅ 前提：兩個向量或矩陣的**形狀（大小）要相同**。

---

### 🔸 向量的「點乘」（Dot Product）

點乘是**兩個向量**相乘後，得到一個「數字（純量）」的運算。這在神經網路中非常常見。

#### ✏️ 例子：
```
A = [1, 2, 3]  
B = [4, 5, 6]

A ⋅ B = 1×4 + 2×5 + 3×6 = 4 + 10 + 18 = 32
```

這是一種「權重加總」的概念，就像神經元接收到的訊號強度。

---

### 🔹 矩陣的「標準乘法」（Matrix Multiplication）

矩陣乘法有點不直覺，但它是非常重要的運算。  
它不是單純的同位置相乘，而是**行乘列、加總後得到新數值**。

#### ✏️ 例子：
```
A = [[1, 2],     B = [[7, 8],
     [3, 4]]          [9, 10]]

A × B = [[1×7 + 2×9, 1×8 + 2×10],
         [3×7 + 4×9, 3×8 + 4×10]]

       = [[25, 28],
          [57, 64]]
```

✅ 前提是：A 的「列數」要等於 B 的「行數」。

---

### 🔸 Hadamard 乘積（逐元素乘法）

Hadamard 乘積是指**矩陣的同位置元素相乘**，結果還是一個矩陣。  
這跟矩陣的標準乘法不一樣！

#### ✏️ 例子：
```
A = [[1, 2],
     [3, 4]]

B = [[5, 6],
     [7, 8]]

A ⊙ B = [[1×5, 2×6],
         [3×7, 4×8]]

       = [[5, 12],
          [21, 32]]
```

✅ 前提：兩個矩陣大小要一樣。

---

### ✅ 總結比較表：

| 運算         | 需求大小相同 | 結果類型     | 特點                     |
|--------------|--------------|--------------|--------------------------|
| 加法         | ✅           | 矩陣或向量   | 同位置相加               |
| 點乘         | ✅（一維向量）| 數字（純量） | 元素相乘後再加總         |
| 矩陣乘法     | 不一定相同   | 矩陣         | 行乘列後加總（線性變換） |
| Hadamard 乘積 | ✅           | 矩陣         | 同位置元素相乘           |

---

如果你需要圖示或想把這些內容整理成簡報，我也可以幫你視覺化喔 😎  
要不要我幫你畫個簡單的對照圖？
